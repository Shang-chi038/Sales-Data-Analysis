{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e89940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "# 1 - Confirming I have pandas\n",
    "\n",
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b53b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sales_data_4.csv creation done.\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from datetime import date\n",
    "\n",
    "def create_sales_data_with_duplicates(file_name):\n",
    "    header_row = ['product_id', 'customer_id', 'customer_age', 'sales_date', 'quantity', 'price']\n",
    "    data_rows = []\n",
    "    \n",
    "    for i in range(65, 91):  # for 26 letters to make it 26 products\n",
    "        \n",
    "        # Randomly introduce missing values (with about 10% chance for each field)\n",
    "        product_id = f'Product {chr(i)}' \n",
    "        customer_id = f'CUST {(i+2)%70 + 1}' \n",
    "        sales_date = f'{date(2026,1,(i-60))}' \n",
    "        quantity = f'{randint(10, 200)}' \n",
    "        price = f'{randint(500,10000)}' \n",
    "        customer_age = f'{randint(18,90)}' \n",
    "\n",
    "        details = [product_id, customer_id, customer_age, sales_date, quantity, price]\n",
    "        data_rows.append(details)\n",
    "\n",
    "    # Adding a few some duplicate rows\n",
    "    for _ in range(7):  # Add 7 duplicate rows\n",
    "        duplicate_row = data_rows[randint(0, len(data_rows) - 1)]\n",
    "        data_rows.append(duplicate_row.copy())\n",
    "    \n",
    "    df = pd.DataFrame(data_rows, columns=header_row)\n",
    "    df.to_csv(file_name, index=False)\n",
    "    print(f\"\\n{file_name} creation done.\")\n",
    "\n",
    "create_sales_data_with_duplicates('sales_data_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "273357c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Load the Data\n",
    "\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"Data loaded successfully.\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b40d351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "\n",
      "--- Checking for Duplicates ---\n",
      "Number of duplicate rows: 7\n",
      "Are there any duplicates? True\n",
      "\n",
      "Duplicate rows:\n",
      "   product_id customer_id  customer_age  sales_date  quantity  price\n",
      "26  Product T     CUST 17            19  2026-01-24        94   7939\n",
      "27  Product K      CUST 8            26  2026-01-15       118   9043\n",
      "28  Product U     CUST 18            55  2026-01-25        26   8364\n",
      "29  Product K      CUST 8            26  2026-01-15       118   9043\n",
      "30  Product T     CUST 17            19  2026-01-24        94   7939\n",
      "31  Product P     CUST 13            29  2026-01-20       182   6408\n",
      "32  Product F      CUST 3            35  2026-01-10       143   5922\n"
     ]
    }
   ],
   "source": [
    "# Checking if the duplicates were created\n",
    "df = load_data('sales_data_4.csv')\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"\\n--- Checking for Duplicates ---\")\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"Are there any duplicates? {df.duplicated().any()}\")\n",
    "\n",
    "# Show the duplicate rows\n",
    "if df.duplicated().any():\n",
    "    print(\"\\nDuplicate rows:\")\n",
    "    print(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7065d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - Implement Duplicate Removal Function\n",
    "\n",
    "def remove_duplicates(dataframe):\n",
    "    initial_shape = dataframe.shape\n",
    "    df = dataframe.drop_duplicates()\n",
    "    final_shape = dataframe.shape\n",
    "    print(f\"Removed {initial_shape[0] - final_shape[0]} duplicate rows.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af6320d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 - Integrating dataframe into the Data Cleaning Pipeline and dropping duplicate rows\n",
    "\n",
    "def load_and_clean_data(file_path):\n",
    "    df = load_data(file_path)\n",
    "    if df is not None:\n",
    "        df = remove_duplicates(df)\n",
    "        return df\n",
    "    else:\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adba3fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "Removed 0 duplicate rows.\n",
      "Cleaned DataFrame shape: (26, 6)\n",
      "  product_id customer_id  customer_age  sales_date  quantity  price\n",
      "0  Product A     CUST 68            53  2026-01-05       152    608\n",
      "1  Product B     CUST 69            68  2026-01-06        75   7974\n",
      "2  Product C     CUST 70            48  2026-01-07        72   5918\n",
      "3  Product D      CUST 1            69  2026-01-08        79   7449\n",
      "4  Product E      CUST 2            43  2026-01-09        66   6590\n"
     ]
    }
   ],
   "source": [
    "# 5 - Testing the Implementation\n",
    "\n",
    "file_path = 'sales_data_4.csv'\n",
    "df = load_and_clean_data(file_path)\n",
    "\n",
    "if df is not None:\n",
    "    print(\"Cleaned DataFrame shape:\", df.shape) # Checking if the duplicates were removed from df\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"Failed to load and clean data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d96ae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving it to a file\n",
    "\n",
    "df.to_csv('sales_data_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f54fd921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "\n",
      "--- Checking for Duplicates ---\n",
      "Number of duplicate rows: 0\n",
      "Are there any duplicates? False\n"
     ]
    }
   ],
   "source": [
    "# Checking if the duplicates were removed\n",
    "df = load_data('sales_data_4.csv')\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"\\n--- Checking for Duplicates ---\")\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"Are there any duplicates? {df.duplicated().any()}\")\n",
    "\n",
    "# Show the duplicate rows\n",
    "if df.duplicated().any():\n",
    "    print(\"\\nDuplicate rows:\")\n",
    "    print(df[df.duplicated()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
